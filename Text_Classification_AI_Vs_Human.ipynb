{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11650,"sourceType":"datasetVersion","datasetId":8327},{"sourceId":8590860,"sourceType":"datasetVersion","datasetId":5138621},{"sourceId":8619145,"sourceType":"datasetVersion","datasetId":5159122}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-05T15:47:25.558936Z","iopub.execute_input":"2024-07-05T15:47:25.559192Z","iopub.status.idle":"2024-07-05T15:47:26.587140Z","shell.execute_reply.started":"2024-07-05T15:47:25.559170Z","shell.execute_reply":"2024-07-05T15:47:26.586167Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/test-data/test_data.json\n/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n/kaggle/input/training-alta/training.json\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-07-05T15:47:31.586154Z","iopub.execute_input":"2024-07-05T15:47:31.586907Z","iopub.status.idle":"2024-07-05T15:47:32.619672Z","shell.execute_reply.started":"2024-07-05T15:47:31.586876Z","shell.execute_reply":"2024-07-05T15:47:32.618751Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Fri Jul  5 15:47:32 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tahap 1: Download Glove 840B 300D","metadata":{}},{"cell_type":"code","source":"# import requests\n# import zipfile\n# import io\n# import os\n\n# # URL of the GloVe embeddings\n# url = \"http://nlp.stanford.edu/data/glove.840B.300d.zip\"\n# # Nama file zip\n# zip_file_name = \"glove.840B.300d.zip\"\n# # Folder where the embeddings will be saved\n# save_folder = \"glove_embeddings\"\n\n# # Create the folder if it does not exist\n# if not os.path.exists(save_folder):\n#     os.makedirs(save_folder)\n\n# # Path to the zip file\n# zip_file_path = os.path.join(save_folder, zip_file_name)\n\n# # Check if the zip file already exists\n# if not os.path.exists(zip_file_path):\n#     # Download the zip file if it does not exist\n#     print(\"Downloading GloVe embeddings...\")\n#     response = requests.get(url)\n#     with open(zip_file_path, 'wb') as f:\n#         f.write(response.content)\n#     print(\"Download complete.\")\n# else:\n#     print(f\"File '{zip_file_path}' already exists, skipping download.\")\n\n# # Extract the zip file\n# print(\"Extracting GloVe embeddings...\")\n# with zipfile.ZipFile(zip_file_path, 'r') as z:\n#     z.extractall(save_folder)\n# print(f\"Extraction complete. Files saved to {save_folder}.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T09:04:11.761885Z","iopub.execute_input":"2024-06-24T09:04:11.762251Z","iopub.status.idle":"2024-06-24T09:04:11.768295Z","shell.execute_reply.started":"2024-06-24T09:04:11.762224Z","shell.execute_reply":"2024-06-24T09:04:11.767038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained GloVe embeddings\nEMBEDDING_DIM = 300\nglove_file = '/kaggle/input/glove840b300dtxt/glove.840B.300d.txt'  # Update with the correct path to the GloVe file\n\nembeddings_index = {}\nwith open(glove_file, encoding='utf-8') as f:\n    for line in f:\n        values = line.split(' ')  # Split the line by space\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs","metadata":{"execution":{"iopub.status.busy":"2024-07-05T15:47:45.792504Z","iopub.execute_input":"2024-07-05T15:47:45.793376Z","iopub.status.idle":"2024-07-05T15:50:48.178659Z","shell.execute_reply.started":"2024-07-05T15:47:45.793342Z","shell.execute_reply":"2024-07-05T15:50:48.177749Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Tahap 2: Import Dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_json(\"/kaggle/input/training-alta/training.json\", lines=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T15:50:56.400977Z","iopub.execute_input":"2024-07-05T15:50:56.401653Z","iopub.status.idle":"2024-07-05T15:50:56.567584Z","shell.execute_reply.started":"2024-07-05T15:50:56.401622Z","shell.execute_reply":"2024-07-05T15:50:56.566626Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text  label  id\n0  Have you ever heard of the Crusades? A time in...      1   0\n1  The professors, who likely have nearly a decad...      1   1\n2  Kemba Walker does a good job of defending Foye...      1   2\n3  Ganias' lawyer, Stanley Twardy, urged the gove...      1   3\n4  The Circuit Court of Appeals of New Jersey had...      0   4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Have you ever heard of the Crusades? A time in...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The professors, who likely have nearly a decad...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kemba Walker does a good job of defending Foye...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ganias' lawyer, Stanley Twardy, urged the gove...</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Circuit Court of Appeals of New Jersey had...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Eksperimen 1: Tidak menggunakan pre-processing","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report \nfrom tensorflow.keras.metrics import categorical_accuracy\n\nimport pandas as pd\nimport numpy as np\n\n# Load the data from a pandas DataFrame\ntexts = df.text.values\nlabels = df.label.values\n\n# Split the data into train and test sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n\n# Tokenize the text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_texts)\ntrain_sequences = tokenizer.texts_to_sequences(train_texts)\ntest_sequences = tokenizer.texts_to_sequences(test_texts)\nword_index = tokenizer.word_index\n\n# Prepare the embedding matrix\nnum_words = len(word_index) + 1\nembedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\n# Pad sequences to have the same length\nmax_length = max([len(seq) for seq in train_sequences + test_sequences])\ntrain_padded_sequences = pad_sequences(train_sequences, maxlen=max_length)\ntest_padded_sequences = pad_sequences(test_sequences, maxlen=max_length)\n\n# # Convert labels to one-hot encoded vectors\n# num_classes = max(labels) + 1\n# train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n# test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)\n\n# Define the embedding layer with pre-trained GloVe embeddings\nwith tf.device(\"/GPU:0\"):\n    embedding_layer = Embedding(num_words,\n                                 EMBEDDING_DIM,\n                                 embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n                                 input_length=max_length,\n                                 trainable=False)\n\n    # Define the LSTM model\n    lstm_model = Sequential([\n        embedding_layer,\n        LSTM(100),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    lstm_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the GRU model\n    gru_model = Sequential([\n        embedding_layer,\n        GRU(100),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    gru_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the combined LSTM-GRU model\n    combined_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100, return_sequences=True)),\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the Bidirectional LSTM model\n    bi_lstm_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_lstm_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the Bidirectional GRU model\n    bi_gru_model = Sequential([\n        embedding_layer,\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_gru_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the combined Bidirectional LSTM and Bidirectional GRU model\n    bi_combined_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100, return_sequences=True)),\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define early stopping callback\n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n    # Train the models\n    lstm_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    gru_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64,  validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    combined_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64,  validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_lstm_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64,  validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_gru_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64,  validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_combined_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64,  validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n\n    # Make predictions on test data\n    lstm_predictions = lstm_model.predict(test_padded_sequences)\n    gru_predictions = gru_model.predict(test_padded_sequences)\n    combined_predictions = combined_model.predict(test_padded_sequences)\n    bi_lstm_predictions = bi_lstm_model.predict(test_padded_sequences)\n    bi_gru_predictions = bi_gru_model.predict(test_padded_sequences)\n    bi_combined_predictions = bi_combined_model.predict(test_padded_sequences)\n\n    # Convert predictions to class labels\n    lstm_predictions = np.round(lstm_predictions)\n    gru_predictions = np.round(gru_predictions)\n    combined_predictions = np.round(combined_predictions)\n    bi_lstm_predictions = np.round(bi_lstm_predictions)\n    bi_gru_predictions = np.round(bi_gru_predictions)\n    bi_combined_predictions = np.round(bi_combined_predictions)\n\n    # Get the true class labels\n#     true_labels = np.argmax(test_labels, axis=1)\n    true_labels = test_labels\n\n    # Print classification reports\n    print(\"LSTM Classification Report:\")\n    print(classification_report(true_labels, lstm_predictions))\n\n    print(\"\\nGRU Classification Report:\")\n    print(classification_report(true_labels, gru_predictions))\n\n    print(\"\\nCombined Classification Report:\")\n    print(classification_report(true_labels, combined_predictions))\n\n    print(\"\\nBi-LSTM Classification Report:\")\n    print(classification_report(true_labels, bi_lstm_predictions))\n\n    print(\"\\nBi-GRU Classification Report:\")\n    print(classification_report(true_labels, bi_gru_predictions))\n\n    print(\"\\nBi-Combined Classification Report:\")\n    print(classification_report(true_labels, bi_combined_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T15:52:15.588851Z","iopub.execute_input":"2024-07-05T15:52:15.589353Z","iopub.status.idle":"2024-07-05T16:01:16.904422Z","shell.execute_reply.started":"2024-07-05T15:52:15.589326Z","shell.execute_reply":"2024-07-05T16:01:16.903498Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-07-05 15:52:17.386415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-05 15:52:17.386535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-05 15:52:17.523173: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - accuracy: 0.8653 - loss: 0.3336 - val_accuracy: 0.9200 - val_loss: 0.2196\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9318 - loss: 0.1800 - val_accuracy: 0.9028 - val_loss: 0.2499\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8728 - loss: 0.3169 - val_accuracy: 0.9161 - val_loss: 0.2076\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9406 - loss: 0.1576 - val_accuracy: 0.9017 - val_loss: 0.2505\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9285 - loss: 0.1875 - val_accuracy: 0.9217 - val_loss: 0.1866\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9397 - loss: 0.1678 - val_accuracy: 0.9189 - val_loss: 0.2038\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9479 - loss: 0.1343 - val_accuracy: 0.9267 - val_loss: 0.1828\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9558 - loss: 0.1175 - val_accuracy: 0.9267 - val_loss: 0.1704\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9651 - loss: 0.0962 - val_accuracy: 0.9278 - val_loss: 0.1832\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9702 - loss: 0.0849 - val_accuracy: 0.9356 - val_loss: 0.1708\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9784 - loss: 0.0661 - val_accuracy: 0.9344 - val_loss: 0.1642\nEpoch 12/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9802 - loss: 0.0578 - val_accuracy: 0.9417 - val_loss: 0.1651\nEpoch 13/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9833 - loss: 0.0496 - val_accuracy: 0.9394 - val_loss: 0.1937\nEpoch 14/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9849 - loss: 0.0466 - val_accuracy: 0.9422 - val_loss: 0.1847\nEpoch 15/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9896 - loss: 0.0345 - val_accuracy: 0.9333 - val_loss: 0.2317\nEpoch 16/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0264 - val_accuracy: 0.9489 - val_loss: 0.1740\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8358 - loss: 0.3825 - val_accuracy: 0.8917 - val_loss: 0.2773\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9106 - loss: 0.2312 - val_accuracy: 0.9156 - val_loss: 0.2027\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9407 - loss: 0.1563 - val_accuracy: 0.9300 - val_loss: 0.1847\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9457 - loss: 0.1411 - val_accuracy: 0.9283 - val_loss: 0.1892\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9607 - loss: 0.1019 - val_accuracy: 0.9317 - val_loss: 0.1822\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9719 - loss: 0.0758 - val_accuracy: 0.9328 - val_loss: 0.1754\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9834 - loss: 0.0495 - val_accuracy: 0.9122 - val_loss: 0.2557\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9850 - loss: 0.0451 - val_accuracy: 0.9272 - val_loss: 0.2353\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9896 - loss: 0.0294 - val_accuracy: 0.9456 - val_loss: 0.1926\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9965 - loss: 0.0143 - val_accuracy: 0.9244 - val_loss: 0.2723\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 0.9233 - val_loss: 0.3155\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - accuracy: 0.8571 - loss: 0.3434 - val_accuracy: 0.9117 - val_loss: 0.2316\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9291 - loss: 0.1911 - val_accuracy: 0.9306 - val_loss: 0.1824\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9436 - loss: 0.1475 - val_accuracy: 0.9350 - val_loss: 0.1761\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9622 - loss: 0.1037 - val_accuracy: 0.9372 - val_loss: 0.1681\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - accuracy: 0.9699 - loss: 0.0868 - val_accuracy: 0.9322 - val_loss: 0.1772\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9773 - loss: 0.0716 - val_accuracy: 0.8744 - val_loss: 0.2998\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9847 - loss: 0.0456 - val_accuracy: 0.9439 - val_loss: 0.1863\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9930 - loss: 0.0224 - val_accuracy: 0.9450 - val_loss: 0.2125\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9942 - loss: 0.0157 - val_accuracy: 0.9306 - val_loss: 0.2728\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.8486 - loss: 0.3570 - val_accuracy: 0.9122 - val_loss: 0.2296\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9256 - loss: 0.1939 - val_accuracy: 0.9194 - val_loss: 0.1979\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9442 - loss: 0.1481 - val_accuracy: 0.9267 - val_loss: 0.1936\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9498 - loss: 0.1287 - val_accuracy: 0.9156 - val_loss: 0.2052\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9552 - loss: 0.1223 - val_accuracy: 0.9333 - val_loss: 0.1763\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9644 - loss: 0.0952 - val_accuracy: 0.9406 - val_loss: 0.1664\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9772 - loss: 0.0691 - val_accuracy: 0.9350 - val_loss: 0.1705\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9798 - loss: 0.0598 - val_accuracy: 0.9267 - val_loss: 0.2205\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9838 - loss: 0.0446 - val_accuracy: 0.9217 - val_loss: 0.2334\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9898 - loss: 0.0315 - val_accuracy: 0.9478 - val_loss: 0.1863\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9940 - loss: 0.0206 - val_accuracy: 0.9378 - val_loss: 0.2298\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.8456 - loss: 0.3862 - val_accuracy: 0.8861 - val_loss: 0.2804\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9039 - loss: 0.2517 - val_accuracy: 0.8789 - val_loss: 0.3076\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9211 - loss: 0.1996 - val_accuracy: 0.9139 - val_loss: 0.2015\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9435 - loss: 0.1438 - val_accuracy: 0.9183 - val_loss: 0.1958\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9542 - loss: 0.1212 - val_accuracy: 0.9322 - val_loss: 0.1695\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9669 - loss: 0.0852 - val_accuracy: 0.9150 - val_loss: 0.2241\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9765 - loss: 0.0616 - val_accuracy: 0.9294 - val_loss: 0.1805\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9801 - loss: 0.0554 - val_accuracy: 0.9261 - val_loss: 0.2009\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9912 - loss: 0.0268 - val_accuracy: 0.9339 - val_loss: 0.2140\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9947 - loss: 0.0176 - val_accuracy: 0.9372 - val_loss: 0.2197\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - accuracy: 0.8595 - loss: 0.3216 - val_accuracy: 0.9200 - val_loss: 0.2139\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9291 - loss: 0.1854 - val_accuracy: 0.9200 - val_loss: 0.2023\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9429 - loss: 0.1509 - val_accuracy: 0.9361 - val_loss: 0.1741\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9554 - loss: 0.1177 - val_accuracy: 0.9367 - val_loss: 0.1629\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - accuracy: 0.9721 - loss: 0.0795 - val_accuracy: 0.9433 - val_loss: 0.1691\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - accuracy: 0.9797 - loss: 0.0586 - val_accuracy: 0.9456 - val_loss: 0.1875\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9857 - loss: 0.0425 - val_accuracy: 0.9417 - val_loss: 0.1874\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9886 - loss: 0.0327 - val_accuracy: 0.9400 - val_loss: 0.2108\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.9939 - loss: 0.0195 - val_accuracy: 0.9444 - val_loss: 0.2099\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\nLSTM Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.90      0.93       874\n           1       0.91      0.97      0.94       926\n\n    accuracy                           0.93      1800\n   macro avg       0.94      0.93      0.93      1800\nweighted avg       0.94      0.93      0.93      1800\n\n\nGRU Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.93      0.93       874\n           1       0.93      0.94      0.93       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nCombined Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.91      0.93       874\n           1       0.92      0.96      0.94       926\n\n    accuracy                           0.94      1800\n   macro avg       0.94      0.94      0.94      1800\nweighted avg       0.94      0.94      0.94      1800\n\n\nBi-LSTM Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.90      0.94       874\n           1       0.91      0.98      0.94       926\n\n    accuracy                           0.94      1800\n   macro avg       0.94      0.94      0.94      1800\nweighted avg       0.94      0.94      0.94      1800\n\n\nBi-GRU Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.89      0.93       874\n           1       0.90      0.97      0.94       926\n\n    accuracy                           0.93      1800\n   macro avg       0.94      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nBi-Combined Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.92      0.93       874\n           1       0.92      0.96      0.94       926\n\n    accuracy                           0.94      1800\n   macro avg       0.94      0.94      0.94      1800\nweighted avg       0.94      0.94      0.94      1800\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df=pd.read_json(\"/kaggle/input/test-data/test_data.json\", lines=True)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:01:16.906054Z","iopub.execute_input":"2024-07-05T16:01:16.906668Z","iopub.status.idle":"2024-07-05T16:01:16.938553Z","shell.execute_reply.started":"2024-07-05T16:01:16.906626Z","shell.execute_reply":"2024-07-05T16:01:16.937678Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   id                                               text\n0   0  Investigators are now hamstrung by the inabili...\n1   1  [10]  Indeed, the District Court found that pe...\n2   2  \"The second object of this legislation is to p...\n3   3  It is in vain, in a case of this nature, that ...\n4   4  *4 Mr. Justice WAYNE delivered the opinion of ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Investigators are now hamstrung by the inabili...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[10]  Indeed, the District Court found that pe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>\"The second object of this legislation is to p...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>It is in vain, in a case of this nature, that ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>*4 Mr. Justice WAYNE delivered the opinion of ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"testing_texts = test_df['text'].tolist()\ntesting_sequences = tokenizer.texts_to_sequences(testing_texts)\ntesting_padded_sequences = pad_sequences(testing_sequences, maxlen=max_length)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:01:16.941386Z","iopub.execute_input":"2024-07-05T16:01:16.941664Z","iopub.status.idle":"2024-07-05T16:01:17.023192Z","shell.execute_reply.started":"2024-07-05T16:01:16.941640Z","shell.execute_reply":"2024-07-05T16:01:17.022330Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def predict_to_json(model, xpad, json_name):\n    probabilities = model.predict(xpad)\n#     answers = np.argmax(probabilities, axis=1)\n    answers = np.round(probabilities).astype(int)\n    answers = np.hstack(answers)\n    answers_df = pd.DataFrame(answers, columns=[\"label\"])\n    answers_df[\"id\"] = range(0, len(answers_df))\n    answers_df = answers_df[[\"id\", \"label\"]]\n    answers_df.to_json(json_name, orient=\"records\", lines=True)\n\npredict_to_json(lstm_model, testing_padded_sequences, \"/kaggle/working/answer_lstm.json\")\npredict_to_json(gru_model, testing_padded_sequences, \"/kaggle/working/answer_gru.json\")\npredict_to_json(combined_model, testing_padded_sequences, \"/kaggle/working/answer_lstmgru.json\")\npredict_to_json(bi_lstm_model, testing_padded_sequences, \"/kaggle/working/answer_bilstm.json\")\npredict_to_json(bi_gru_model, testing_padded_sequences, \"/kaggle/working/answer_bigru.json\")\npredict_to_json(bi_combined_model, testing_padded_sequences, \"/kaggle/working/answer_bilstmbigru.json\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:01:17.025088Z","iopub.execute_input":"2024-07-05T16:01:17.025440Z","iopub.status.idle":"2024-07-05T16:01:21.470927Z","shell.execute_reply.started":"2024-07-05T16:01:17.025407Z","shell.execute_reply":"2024-07-05T16:01:21.470191Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Eksperimen 2: Menggunkan preprocessing Lowercasing, remove number and punctuation","metadata":{}},{"cell_type":"markdown","source":"### Preprocessing untuk eksperimen 2 dan 3 ","metadata":{}},{"cell_type":"code","source":"import re \nimport string\n\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Preprocessing text\ndef preprocess_text(text):\n    text = text.lower()  # Convert text to lowercase\n    text = re.sub(r'[^\\w\\s?!,\\']', '', text) # Remove punctuation\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    return text\n\n# Preprocessing text + stopwords\ndef preprocess_text_stopwords(text):\n    text = text.lower()  # Convert text to lowercase\n    text = re.sub(r'[^\\w\\s?!,\\']', '', text) # Remove punctuation\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:05:09.238919Z","iopub.execute_input":"2024-07-05T16:05:09.239315Z","iopub.status.idle":"2024-07-05T16:05:10.159841Z","shell.execute_reply.started":"2024-07-05T16:05:09.239261Z","shell.execute_reply":"2024-07-05T16:05:10.158719Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"def roc_auc(predictions,target):\n    '''\n    This methods returns the AUC Score when given the Predictions\n    and Labels\n    '''\n    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n    roc_auc = metrics.auc(fpr, tpr)\n    return roc_auc","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:05:11.724665Z","iopub.execute_input":"2024-07-05T16:05:11.725328Z","iopub.status.idle":"2024-07-05T16:05:11.730833Z","shell.execute_reply.started":"2024-07-05T16:05:11.725297Z","shell.execute_reply":"2024-07-05T16:05:11.729788Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df['prep_text'] = df['text'].apply(preprocess_text)\ndf['prep_sw_text'] = df['text'].apply(preprocess_text_stopwords)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:05:13.524071Z","iopub.execute_input":"2024-07-05T16:05:13.524443Z","iopub.status.idle":"2024-07-05T16:05:14.462681Z","shell.execute_reply.started":"2024-07-05T16:05:13.524415Z","shell.execute_reply":"2024-07-05T16:05:14.461787Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                text  label  id  \\\n0  Have you ever heard of the Crusades? A time in...      1   0   \n1  The professors, who likely have nearly a decad...      1   1   \n2  Kemba Walker does a good job of defending Foye...      1   2   \n3  Ganias' lawyer, Stanley Twardy, urged the gove...      1   3   \n4  The Circuit Court of Appeals of New Jersey had...      0   4   \n\n                                           prep_text  \\\n0  have you ever heard of the crusades? a time in...   \n1  the professors, who likely have nearly a decad...   \n2  kemba walker does a good job of defending foye...   \n3  ganias' lawyer, stanley twardy, urged the gove...   \n4  the circuit court of appeals of new jersey had...   \n\n                                        prep_sw_text  \n0  ever heard crusades? time christians went year...  \n1  professors, likely nearly decade education eac...  \n2  kemba walker good job defending foye, better o...  \n3  ganias' lawyer, stanley twardy, urged governme...  \n4  circuit court appeals new jersey jurisdiction ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>id</th>\n      <th>prep_text</th>\n      <th>prep_sw_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Have you ever heard of the Crusades? A time in...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>have you ever heard of the crusades? a time in...</td>\n      <td>ever heard crusades? time christians went year...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The professors, who likely have nearly a decad...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>the professors, who likely have nearly a decad...</td>\n      <td>professors, likely nearly decade education eac...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kemba Walker does a good job of defending Foye...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>kemba walker does a good job of defending foye...</td>\n      <td>kemba walker good job defending foye, better o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ganias' lawyer, Stanley Twardy, urged the gove...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>ganias' lawyer, stanley twardy, urged the gove...</td>\n      <td>ganias' lawyer, stanley twardy, urged governme...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Circuit Court of Appeals of New Jersey had...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>the circuit court of appeals of new jersey had...</td>\n      <td>circuit court appeals new jersey jurisdiction ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Preprocessing Test Data\ndf_test = pd.read_json(\"/kaggle/input/test-data/test_data.json\", lines=True)\n\ndf_test['prep_text'] = df_test['text'].apply(preprocess_text)\ndf_test['prep_sw_text'] = df_test['text'].apply(preprocess_text_stopwords)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:05:14.721006Z","iopub.execute_input":"2024-07-05T16:05:14.721856Z","iopub.status.idle":"2024-07-05T16:05:14.850572Z","shell.execute_reply.started":"2024-07-05T16:05:14.721824Z","shell.execute_reply":"2024-07-05T16:05:14.849494Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   id                                               text  \\\n0   0  Investigators are now hamstrung by the inabili...   \n1   1  [10]  Indeed, the District Court found that pe...   \n2   2  \"The second object of this legislation is to p...   \n3   3  It is in vain, in a case of this nature, that ...   \n4   4  *4 Mr. Justice WAYNE delivered the opinion of ...   \n\n                                           prep_text  \\\n0  investigators are now hamstrung by the inabili...   \n1    indeed, the district court found that petiti...   \n2  the second object of this legislation is to pr...   \n3  it is in vain, in a case of this nature, that ...   \n4   mr justice wayne delivered the opinion of the...   \n\n                                        prep_sw_text  \n0  investigators hamstrung inability compel witne...  \n1  indeed, district court found petitioners able ...  \n2  second object legislation protect employees ra...  \n3  vain, case nature, court look intentions legis...  \n4           mr justice wayne delivered opinion court  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>prep_text</th>\n      <th>prep_sw_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Investigators are now hamstrung by the inabili...</td>\n      <td>investigators are now hamstrung by the inabili...</td>\n      <td>investigators hamstrung inability compel witne...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[10]  Indeed, the District Court found that pe...</td>\n      <td>indeed, the district court found that petiti...</td>\n      <td>indeed, district court found petitioners able ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>\"The second object of this legislation is to p...</td>\n      <td>the second object of this legislation is to pr...</td>\n      <td>second object legislation protect employees ra...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>It is in vain, in a case of this nature, that ...</td>\n      <td>it is in vain, in a case of this nature, that ...</td>\n      <td>vain, case nature, court look intentions legis...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>*4 Mr. Justice WAYNE delivered the opinion of ...</td>\n      <td>mr justice wayne delivered the opinion of the...</td>\n      <td>mr justice wayne delivered opinion court</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report \nfrom tensorflow.keras.metrics import categorical_accuracy\n\nimport pandas as pd\nimport numpy as np\n\n# Load the data from a pandas DataFrame\ntexts = df.prep_text.values\nlabels = df.label.values\n\n# Split the data into train and test sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n\n# Tokenize the text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_texts)\ntrain_sequences = tokenizer.texts_to_sequences(train_texts)\ntest_sequences = tokenizer.texts_to_sequences(test_texts)\nword_index = tokenizer.word_index\n\n# Prepare the embedding matrix\nnum_words = len(word_index) + 1\nembedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\n# Pad sequences to have the same length\nmax_length = max([len(seq) for seq in train_sequences + test_sequences])\ntrain_padded_sequences = pad_sequences(train_sequences, maxlen=max_length)\ntest_padded_sequences = pad_sequences(test_sequences, maxlen=max_length)\n\n# # Convert labels to one-hot encoded vectors\n# num_classes = max(labels) + 1\n# train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n# test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)\n\n# Define the embedding layer with pre-trained GloVe embeddings\nwith tf.device(\"/GPU:0\"):\n    embedding_layer = Embedding(num_words,\n                                 EMBEDDING_DIM,\n                                 embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n                                 input_length=max_length,\n                                 trainable=False)\n\n    # Define the LSTM model\n    lstm_model = Sequential([\n        embedding_layer,\n        LSTM(100),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    lstm_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the GRU model\n    gru_model = Sequential([\n        embedding_layer,\n        GRU(100),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    gru_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the combined LSTM-GRU model\n    combined_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100, return_sequences=True)),\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the Bidirectional LSTM model\n    bi_lstm_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_lstm_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the Bidirectional GRU model\n    bi_gru_model = Sequential([\n        embedding_layer,\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_gru_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the combined Bidirectional LSTM and Bidirectional GRU model\n    bi_combined_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100, return_sequences=True)),\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define early stopping callback\n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n    # Train the models\n    lstm_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    gru_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    combined_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_lstm_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_gru_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_combined_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n\n    # Make predictions on test data\n    lstm_predictions = lstm_model.predict(test_padded_sequences)\n    gru_predictions = gru_model.predict(test_padded_sequences)\n    combined_predictions = combined_model.predict(test_padded_sequences)\n    bi_lstm_predictions = bi_lstm_model.predict(test_padded_sequences)\n    bi_gru_predictions = bi_gru_model.predict(test_padded_sequences)\n    bi_combined_predictions = bi_combined_model.predict(test_padded_sequences)\n\n    # Convert predictions to class labels\n    lstm_predictions = np.round(lstm_predictions)\n    gru_predictions = np.round(gru_predictions)\n    combined_predictions = np.round(combined_predictions)\n    bi_lstm_predictions = np.round(bi_lstm_predictions)\n    bi_gru_predictions = np.round(bi_gru_predictions)\n    bi_combined_predictions = np.round(bi_combined_predictions)\n\n    # Get the true class labels\n#     true_labels = np.argmax(test_labels, axis=1)\n    true_labels = test_labels\n\n    # Print classification reports\n    print(\"LSTM Classification Report:\")\n    print(classification_report(true_labels, lstm_predictions))\n\n    print(\"\\nGRU Classification Report:\")\n    print(classification_report(true_labels, gru_predictions))\n\n    print(\"\\nCombined Classification Report:\")\n    print(classification_report(true_labels, combined_predictions))\n\n    print(\"\\nBi-LSTM Classification Report:\")\n    print(classification_report(true_labels, bi_lstm_predictions))\n\n    print(\"\\nBi-GRU Classification Report:\")\n    print(classification_report(true_labels, bi_gru_predictions))\n\n    print(\"\\nBi-Combined Classification Report:\")\n    print(classification_report(true_labels, bi_combined_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:05:18.524427Z","iopub.execute_input":"2024-07-05T16:05:18.524806Z","iopub.status.idle":"2024-07-05T16:14:19.842205Z","shell.execute_reply.started":"2024-07-05T16:05:18.524775Z","shell.execute_reply":"2024-07-05T16:14:19.841234Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.8410 - loss: 0.3791 - val_accuracy: 0.9089 - val_loss: 0.2460\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9140 - loss: 0.2253 - val_accuracy: 0.9194 - val_loss: 0.2044\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9351 - loss: 0.1681 - val_accuracy: 0.9222 - val_loss: 0.1840\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9403 - loss: 0.1512 - val_accuracy: 0.9178 - val_loss: 0.2074\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9509 - loss: 0.1203 - val_accuracy: 0.9328 - val_loss: 0.1756\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9696 - loss: 0.0860 - val_accuracy: 0.9328 - val_loss: 0.1787\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9711 - loss: 0.0836 - val_accuracy: 0.8817 - val_loss: 0.2908\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9462 - loss: 0.1309 - val_accuracy: 0.9283 - val_loss: 0.1881\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9850 - loss: 0.0504 - val_accuracy: 0.9344 - val_loss: 0.1877\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9873 - loss: 0.0431 - val_accuracy: 0.9450 - val_loss: 0.1768\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8338 - loss: 0.3848 - val_accuracy: 0.8828 - val_loss: 0.2847\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8984 - loss: 0.2561 - val_accuracy: 0.8989 - val_loss: 0.2438\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9269 - loss: 0.1859 - val_accuracy: 0.8928 - val_loss: 0.2824\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9463 - loss: 0.1385 - val_accuracy: 0.9300 - val_loss: 0.1737\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9571 - loss: 0.1163 - val_accuracy: 0.9350 - val_loss: 0.1632\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9688 - loss: 0.0840 - val_accuracy: 0.9400 - val_loss: 0.1662\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9774 - loss: 0.0588 - val_accuracy: 0.9372 - val_loss: 0.1741\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9865 - loss: 0.0412 - val_accuracy: 0.9417 - val_loss: 0.1835\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0275 - val_accuracy: 0.9483 - val_loss: 0.1982\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9916 - loss: 0.0236 - val_accuracy: 0.9539 - val_loss: 0.1802\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - accuracy: 0.8624 - loss: 0.3472 - val_accuracy: 0.9089 - val_loss: 0.2502\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9286 - loss: 0.1894 - val_accuracy: 0.9250 - val_loss: 0.1881\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9475 - loss: 0.1456 - val_accuracy: 0.9250 - val_loss: 0.2010\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9557 - loss: 0.1143 - val_accuracy: 0.9333 - val_loss: 0.1827\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9687 - loss: 0.0833 - val_accuracy: 0.9311 - val_loss: 0.1908\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9832 - loss: 0.0494 - val_accuracy: 0.9261 - val_loss: 0.2089\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9884 - loss: 0.0357 - val_accuracy: 0.9483 - val_loss: 0.1764\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9902 - loss: 0.0298 - val_accuracy: 0.9494 - val_loss: 0.1801\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9895 - loss: 0.0299 - val_accuracy: 0.9533 - val_loss: 0.2076\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9941 - loss: 0.0169 - val_accuracy: 0.9489 - val_loss: 0.2219\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9957 - loss: 0.0146 - val_accuracy: 0.9356 - val_loss: 0.2676\nEpoch 12/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9951 - loss: 0.0156 - val_accuracy: 0.9561 - val_loss: 0.2122\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.8445 - loss: 0.3742 - val_accuracy: 0.9089 - val_loss: 0.2388\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9259 - loss: 0.1994 - val_accuracy: 0.9156 - val_loss: 0.2143\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9325 - loss: 0.1704 - val_accuracy: 0.9239 - val_loss: 0.1891\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9462 - loss: 0.1435 - val_accuracy: 0.9244 - val_loss: 0.1919\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9533 - loss: 0.1210 - val_accuracy: 0.9322 - val_loss: 0.1743\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9644 - loss: 0.0968 - val_accuracy: 0.9328 - val_loss: 0.1692\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9709 - loss: 0.0825 - val_accuracy: 0.9383 - val_loss: 0.1814\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9815 - loss: 0.0588 - val_accuracy: 0.9378 - val_loss: 0.1829\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9853 - loss: 0.0441 - val_accuracy: 0.9433 - val_loss: 0.1786\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9904 - loss: 0.0300 - val_accuracy: 0.9372 - val_loss: 0.2050\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9931 - loss: 0.0224 - val_accuracy: 0.9494 - val_loss: 0.2085\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.8273 - loss: 0.4005 - val_accuracy: 0.8789 - val_loss: 0.3008\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.8980 - loss: 0.2597 - val_accuracy: 0.8917 - val_loss: 0.2777\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9153 - loss: 0.2066 - val_accuracy: 0.9172 - val_loss: 0.2098\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9439 - loss: 0.1449 - val_accuracy: 0.9322 - val_loss: 0.1741\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9588 - loss: 0.1141 - val_accuracy: 0.9333 - val_loss: 0.1699\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9672 - loss: 0.0839 - val_accuracy: 0.9233 - val_loss: 0.1912\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9768 - loss: 0.0648 - val_accuracy: 0.9333 - val_loss: 0.1661\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9709 - loss: 0.0830 - val_accuracy: 0.9311 - val_loss: 0.1782\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9878 - loss: 0.0374 - val_accuracy: 0.9467 - val_loss: 0.2019\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9917 - loss: 0.0239 - val_accuracy: 0.9417 - val_loss: 0.2020\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0165 - val_accuracy: 0.9322 - val_loss: 0.2102\nEpoch 12/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9967 - loss: 0.0126 - val_accuracy: 0.9500 - val_loss: 0.2180\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - accuracy: 0.8540 - loss: 0.3384 - val_accuracy: 0.9067 - val_loss: 0.2343\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9339 - loss: 0.1793 - val_accuracy: 0.9228 - val_loss: 0.1976\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9445 - loss: 0.1448 - val_accuracy: 0.9289 - val_loss: 0.1965\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9588 - loss: 0.1096 - val_accuracy: 0.9317 - val_loss: 0.1788\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9724 - loss: 0.0763 - val_accuracy: 0.9317 - val_loss: 0.1812\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9804 - loss: 0.0550 - val_accuracy: 0.9378 - val_loss: 0.1907\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9869 - loss: 0.0382 - val_accuracy: 0.9267 - val_loss: 0.2504\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9915 - loss: 0.0270 - val_accuracy: 0.9311 - val_loss: 0.2411\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9948 - loss: 0.0151 - val_accuracy: 0.9367 - val_loss: 0.2370\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\nLSTM Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.92      0.93       874\n           1       0.92      0.95      0.94       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nGRU Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.91      0.93       874\n           1       0.92      0.96      0.94       926\n\n    accuracy                           0.94      1800\n   macro avg       0.94      0.93      0.93      1800\nweighted avg       0.94      0.94      0.93      1800\n\n\nCombined Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.95      0.95       874\n           1       0.95      0.95      0.95       926\n\n    accuracy                           0.95      1800\n   macro avg       0.95      0.95      0.95      1800\nweighted avg       0.95      0.95      0.95      1800\n\n\nBi-LSTM Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.91      0.93       874\n           1       0.91      0.96      0.94       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nBi-GRU Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.92      0.93       874\n           1       0.93      0.95      0.94       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nBi-Combined Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.92      0.93       874\n           1       0.92      0.95      0.93       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_texts = df_test['prep_text'].tolist()\ntesting_sequences = tokenizer.texts_to_sequences(testing_texts)\ntesting_padded_sequences = pad_sequences(testing_sequences, maxlen=max_length)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:14:19.843953Z","iopub.execute_input":"2024-07-05T16:14:19.844255Z","iopub.status.idle":"2024-07-05T16:14:19.921859Z","shell.execute_reply.started":"2024-07-05T16:14:19.844213Z","shell.execute_reply":"2024-07-05T16:14:19.921104Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def predict_to_json(model, xpad, json_name):\n    probabilities = model.predict(xpad)\n#     answers = np.argmax(probabilities, axis=1)\n    answers = np.round(probabilities).astype(int)\n    answers = np.hstack(answers)\n    answers_df = pd.DataFrame(answers, columns=[\"label\"])\n    answers_df[\"id\"] = range(0, len(answers_df))\n    answers_df = answers_df[[\"id\", \"label\"]]\n    answers_df.to_json(json_name, orient=\"records\", lines=True)\n\npredict_to_json(lstm_model, testing_padded_sequences, \"/kaggle/working/answer_lstm2.json\")\npredict_to_json(gru_model, testing_padded_sequences, \"/kaggle/working/answer_gru2.json\")\npredict_to_json(combined_model, testing_padded_sequences, \"/kaggle/working/answer_lstmgru2.json\")\npredict_to_json(bi_lstm_model, testing_padded_sequences, \"/kaggle/working/answer_bilstm2.json\")\npredict_to_json(bi_gru_model, testing_padded_sequences, \"/kaggle/working/answer_bigru2.json\")\npredict_to_json(bi_combined_model, testing_padded_sequences, \"/kaggle/working/answer_bilstmbigru2.json\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:14:19.923108Z","iopub.execute_input":"2024-07-05T16:14:19.923548Z","iopub.status.idle":"2024-07-05T16:14:24.219017Z","shell.execute_reply.started":"2024-07-05T16:14:19.923516Z","shell.execute_reply":"2024-07-05T16:14:24.218127Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Eksperimen 3\n- Preprocesing tambahan menggunakan Stopwords","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report \nfrom tensorflow.keras.metrics import categorical_accuracy\n\nimport pandas as pd\nimport numpy as np\n\n# Load the data from a pandas DataFrame\ntexts = df.prep_sw_text.values\nlabels = df.label.values\n\n# Split the data into train and test sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n\n# Tokenize the text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_texts)\ntrain_sequences = tokenizer.texts_to_sequences(train_texts)\ntest_sequences = tokenizer.texts_to_sequences(test_texts)\nword_index = tokenizer.word_index\n\n# Prepare the embedding matrix\nnum_words = len(word_index) + 1\nembedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\n# Pad sequences to have the same length\nmax_length = max([len(seq) for seq in train_sequences + test_sequences])\ntrain_padded_sequences = pad_sequences(train_sequences, maxlen=max_length)\ntest_padded_sequences = pad_sequences(test_sequences, maxlen=max_length)\n\n# # Convert labels to one-hot encoded vectors\n# num_classes = max(labels) + 1\n# train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n# test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)\n\n# Define the embedding layer with pre-trained GloVe embeddings\nwith tf.device(\"/GPU:0\"):\n    embedding_layer = Embedding(num_words,\n                                 EMBEDDING_DIM,\n                                 embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n                                 input_length=max_length,\n                                 trainable=False)\n\n    # Define the LSTM model\n    lstm_model = Sequential([\n        embedding_layer,\n        LSTM(100),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    lstm_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the GRU model\n    gru_model = Sequential([\n        embedding_layer,\n        GRU(100),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    gru_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the combined LSTM-GRU model\n    combined_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100, return_sequences=True)),\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the Bidirectional LSTM model\n    bi_lstm_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_lstm_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the Bidirectional GRU model\n    bi_gru_model = Sequential([\n        embedding_layer,\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_gru_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define the combined Bidirectional LSTM and Bidirectional GRU model\n    bi_combined_model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100, return_sequences=True)),\n        Bidirectional(GRU(100)),\n        Dropout(0.3),\n        Dense(1, activation='sigmoid')\n    ])\n    optimizer = Adam(learning_rate=0.001)\n    bi_combined_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Define early stopping callback\n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n    # Train the models\n    lstm_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    gru_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    combined_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_lstm_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_gru_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n    \n    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n    bi_combined_model.fit(train_padded_sequences, train_labels, epochs=20, batch_size=64, validation_data=(test_padded_sequences, test_labels), callbacks=[early_stop])\n\n    # Make predictions on test data\n    lstm_predictions = lstm_model.predict(test_padded_sequences)\n    gru_predictions = gru_model.predict(test_padded_sequences)\n    combined_predictions = combined_model.predict(test_padded_sequences)\n    bi_lstm_predictions = bi_lstm_model.predict(test_padded_sequences)\n    bi_gru_predictions = bi_gru_model.predict(test_padded_sequences)\n    bi_combined_predictions = bi_combined_model.predict(test_padded_sequences)\n\n    # Convert predictions to class labels\n    lstm_predictions = np.round(lstm_predictions)\n    gru_predictions = np.round(gru_predictions)\n    combined_predictions = np.round(combined_predictions)\n    bi_lstm_predictions = np.round(bi_lstm_predictions)\n    bi_gru_predictions = np.round(bi_gru_predictions)\n    bi_combined_predictions = np.round(bi_combined_predictions)\n\n    # Get the true class labels\n#     true_labels = np.argmax(test_labels, axis=1)\n    true_labels = test_labels\n\n    # Print classification reports\n    print(\"LSTM Classification Report:\")\n    print(classification_report(true_labels, lstm_predictions))\n\n    print(\"\\nGRU Classification Report:\")\n    print(classification_report(true_labels, gru_predictions))\n\n    print(\"\\nCombined Classification Report:\")\n    print(classification_report(true_labels, combined_predictions))\n\n    print(\"\\nBi-LSTM Classification Report:\")\n    print(classification_report(true_labels, bi_lstm_predictions))\n\n    print(\"\\nBi-GRU Classification Report:\")\n    print(classification_report(true_labels, bi_gru_predictions))\n\n    print(\"\\nBi-Combined Classification Report:\")\n    print(classification_report(true_labels, bi_combined_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:14:24.221069Z","iopub.execute_input":"2024-07-05T16:14:24.221391Z","iopub.status.idle":"2024-07-05T16:19:20.573198Z","shell.execute_reply.started":"2024-07-05T16:14:24.221365Z","shell.execute_reply":"2024-07-05T16:19:20.572197Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8669 - loss: 0.3314 - val_accuracy: 0.9167 - val_loss: 0.2160\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9271 - loss: 0.1927 - val_accuracy: 0.9206 - val_loss: 0.1983\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9412 - loss: 0.1481 - val_accuracy: 0.9267 - val_loss: 0.1897\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9526 - loss: 0.1251 - val_accuracy: 0.9267 - val_loss: 0.1851\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.0964 - val_accuracy: 0.9289 - val_loss: 0.1918\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9701 - loss: 0.0796 - val_accuracy: 0.9333 - val_loss: 0.1853\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0592 - val_accuracy: 0.9356 - val_loss: 0.1724\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9886 - loss: 0.0383 - val_accuracy: 0.9383 - val_loss: 0.1930\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9900 - loss: 0.0330 - val_accuracy: 0.9400 - val_loss: 0.2243\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0188 - val_accuracy: 0.9400 - val_loss: 0.2098\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0194 - val_accuracy: 0.8867 - val_loss: 0.2986\nEpoch 12/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9588 - loss: 0.1075 - val_accuracy: 0.9422 - val_loss: 0.2091\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8461 - loss: 0.3662 - val_accuracy: 0.8928 - val_loss: 0.2744\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9046 - loss: 0.2441 - val_accuracy: 0.9189 - val_loss: 0.2028\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9362 - loss: 0.1712 - val_accuracy: 0.9217 - val_loss: 0.1961\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9486 - loss: 0.1365 - val_accuracy: 0.9306 - val_loss: 0.1749\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.1061 - val_accuracy: 0.9250 - val_loss: 0.1772\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0748 - val_accuracy: 0.9194 - val_loss: 0.1946\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0542 - val_accuracy: 0.9261 - val_loss: 0.1990\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.0368 - val_accuracy: 0.9239 - val_loss: 0.2258\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0253 - val_accuracy: 0.9317 - val_loss: 0.2334\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.8696 - loss: 0.3165 - val_accuracy: 0.9117 - val_loss: 0.2331\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9321 - loss: 0.1768 - val_accuracy: 0.9083 - val_loss: 0.2306\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9496 - loss: 0.1385 - val_accuracy: 0.9322 - val_loss: 0.1862\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9619 - loss: 0.0959 - val_accuracy: 0.9061 - val_loss: 0.2247\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9794 - loss: 0.0572 - val_accuracy: 0.9367 - val_loss: 0.1940\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9862 - loss: 0.0415 - val_accuracy: 0.9344 - val_loss: 0.2204\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9920 - loss: 0.0243 - val_accuracy: 0.9322 - val_loss: 0.2671\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9930 - loss: 0.0204 - val_accuracy: 0.9289 - val_loss: 0.2795\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8569 - loss: 0.3440 - val_accuracy: 0.9183 - val_loss: 0.2196\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9261 - loss: 0.1926 - val_accuracy: 0.9156 - val_loss: 0.2090\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9373 - loss: 0.1601 - val_accuracy: 0.9206 - val_loss: 0.1888\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9543 - loss: 0.1235 - val_accuracy: 0.9294 - val_loss: 0.1801\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9599 - loss: 0.0999 - val_accuracy: 0.9317 - val_loss: 0.1720\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9783 - loss: 0.0630 - val_accuracy: 0.9389 - val_loss: 0.1711\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9846 - loss: 0.0478 - val_accuracy: 0.9383 - val_loss: 0.1798\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9896 - loss: 0.0343 - val_accuracy: 0.9378 - val_loss: 0.1952\nEpoch 9/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9959 - loss: 0.0178 - val_accuracy: 0.9356 - val_loss: 0.1994\nEpoch 10/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9927 - loss: 0.0223 - val_accuracy: 0.9356 - val_loss: 0.2449\nEpoch 11/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9954 - loss: 0.0153 - val_accuracy: 0.9428 - val_loss: 0.2248\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8244 - loss: 0.3857 - val_accuracy: 0.8889 - val_loss: 0.2799\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9057 - loss: 0.2409 - val_accuracy: 0.9172 - val_loss: 0.2046\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9345 - loss: 0.1695 - val_accuracy: 0.9272 - val_loss: 0.1859\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9453 - loss: 0.1391 - val_accuracy: 0.9233 - val_loss: 0.1930\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9597 - loss: 0.1046 - val_accuracy: 0.9233 - val_loss: 0.1909\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9692 - loss: 0.0829 - val_accuracy: 0.9244 - val_loss: 0.1961\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9794 - loss: 0.0580 - val_accuracy: 0.9328 - val_loss: 0.1871\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9853 - loss: 0.0425 - val_accuracy: 0.9250 - val_loss: 0.2406\nEpoch 1/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.8704 - loss: 0.3212 - val_accuracy: 0.9183 - val_loss: 0.2149\nEpoch 2/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9321 - loss: 0.1786 - val_accuracy: 0.9178 - val_loss: 0.2040\nEpoch 3/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9444 - loss: 0.1459 - val_accuracy: 0.9211 - val_loss: 0.1945\nEpoch 4/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9664 - loss: 0.0936 - val_accuracy: 0.9250 - val_loss: 0.1978\nEpoch 5/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9756 - loss: 0.0692 - val_accuracy: 0.9278 - val_loss: 0.2144\nEpoch 6/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9861 - loss: 0.0387 - val_accuracy: 0.9272 - val_loss: 0.2046\nEpoch 7/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9918 - loss: 0.0296 - val_accuracy: 0.9044 - val_loss: 0.3128\nEpoch 8/20\n\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9926 - loss: 0.0227 - val_accuracy: 0.9217 - val_loss: 0.2810\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\nLSTM Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.93      0.93       874\n           1       0.94      0.94      0.94       926\n\n    accuracy                           0.94      1800\n   macro avg       0.94      0.94      0.94      1800\nweighted avg       0.94      0.94      0.94      1800\n\n\nGRU Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.90      0.93       874\n           1       0.91      0.96      0.93       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nCombined Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.92      0.93       874\n           1       0.92      0.95      0.93       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nBi-LSTM Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.93      0.94       874\n           1       0.94      0.95      0.94       926\n\n    accuracy                           0.94      1800\n   macro avg       0.94      0.94      0.94      1800\nweighted avg       0.94      0.94      0.94      1800\n\n\nBi-GRU Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.90      0.92       874\n           1       0.91      0.96      0.93       926\n\n    accuracy                           0.93      1800\n   macro avg       0.93      0.93      0.93      1800\nweighted avg       0.93      0.93      0.93      1800\n\n\nBi-Combined Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.92      0.91      0.92       874\n           1       0.92      0.93      0.92       926\n\n    accuracy                           0.92      1800\n   macro avg       0.92      0.92      0.92      1800\nweighted avg       0.92      0.92      0.92      1800\n\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_texts = df_test['prep_sw_text'].tolist()\ntesting_sequences = tokenizer.texts_to_sequences(testing_texts)\ntesting_padded_sequences = pad_sequences(testing_sequences, maxlen=max_length)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:19:20.574359Z","iopub.execute_input":"2024-07-05T16:19:20.574652Z","iopub.status.idle":"2024-07-05T16:19:20.632908Z","shell.execute_reply.started":"2024-07-05T16:19:20.574627Z","shell.execute_reply":"2024-07-05T16:19:20.631959Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def predict_to_json(model, xpad, json_name):\n    probabilities = model.predict(xpad)\n#     answers = np.argmax(probabilities, axis=1)\n    answers = np.round(probabilities).astype(int)\n    answers = np.hstack(answers)\n    answers_df = pd.DataFrame(answers, columns=[\"label\"])\n    answers_df[\"id\"] = range(0, len(answers_df))\n    answers_df = answers_df[[\"id\", \"label\"]]\n    answers_df.to_json(json_name, orient=\"records\", lines=True)\n\npredict_to_json(lstm_model, testing_padded_sequences, \"/kaggle/working/answer_lstm3.json\")\npredict_to_json(gru_model, testing_padded_sequences, \"/kaggle/working/answer_gru3.json\")\npredict_to_json(combined_model, testing_padded_sequences, \"/kaggle/working/answer_lstmgru3.json\")\npredict_to_json(bi_lstm_model, testing_padded_sequences, \"/kaggle/working/answer_bilstm3.json\")\npredict_to_json(bi_gru_model, testing_padded_sequences, \"/kaggle/working/answer_bigru3.json\")\npredict_to_json(bi_combined_model, testing_padded_sequences, \"/kaggle/working/answer_bilstmbigru3.json\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:19:20.634331Z","iopub.execute_input":"2024-07-05T16:19:20.634691Z","iopub.status.idle":"2024-07-05T16:19:23.390516Z","shell.execute_reply.started":"2024-07-05T16:19:20.634660Z","shell.execute_reply":"2024-07-05T16:19:23.389775Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}